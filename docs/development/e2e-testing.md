# End-to-End Testing

## Overview

The end-to-end testing feature provides a comprehensive test infrastructure for
validating carburetor's two-way sync between PostgreSQL backend and SQLite
clients. This addresses a fundamental architectural constraint: the `backend`
and `client` features cannot coexist in the same crate due to Cargo's feature
unification behavior.

The solution employs a hybrid architecture where the backend runs as a separate
RPC server process while client code executes directly in the test suite. This
enables realistic multi-client sync scenarios without feature flag conflicts:

- **Backend Server**: A standalone binary crate with the `backend` feature that
  exposes sync operations via tarpc RPC service
- **Direct Client Access**: The test suite depends on the schema crate with the
  `client` feature, enabling direct use of generated client functions

This architecture provides isolation between feature flags (separate processes)
while maintaining ergonomic access to client-side generated code for test
assertions and orchestration.

## Core Implementation Library/Framework/Tool

| Library/Framework/Tool | Purpose |
|---|---|
| tarpc 0.* | RPC framework for type-safe communication between test suite and backend server |
| testcontainers-rs 0.* | Ephemeral PostgreSQL containers for isolated backend database per test |
| diesel 2.* | Direct database access for server/client instances |

## Feature Components

### Sample Schema

A shared schema crate defines the `carburetor_sync_config!` macro invocation
used by both the backend server and test suite. This ensures consistent table
definitions and sync group configurations across the test infrastructure.

The schema crate supports both feature flags but is compiled separately for each
consumer:

- Backend server compiles with `--features backend`
- Test suite compiles with `--features client`

### Sample Backend Server

A standalone binary crate wraps the generated backend functions in a tarpc RPC
service. The service trait definition is shared between the backend server and
test suite, ensuring type-safe communication without manual serialization.

The server exposes three categories of RPC methods:

**Generated Function Methods**: Each backend function generated by the macro
(e.g., `process_upload_request`, `process_download_request`) is exposed as an
RPC method, allowing tests to perform sync operations via tarpc.

**Query Methods**: Methods for reading backend database state to verify test
assertions, such as retrieving specific records or listing all records in a
table.

**Test Helper Methods**: Methods for directly manipulating the backend database
in specific ways needed for test setup, such as resetting tables or
inserting/updating/deleting records that bypass the normal sync flow.

The tarpc service trait is defined in a shared location accessible to both the
backend and test suite. This approach eliminates the need for OpenAPI
specification generation and provides compile-time type safety for all RPC
calls.

### E2E Test Suite with Direct Client Access

The test suite crate depends on `sample-test-core` with the `client` feature,
enabling direct access to generated client functions without serialization
overhead for local operations.

**Local Operations**: Tests call generated functions directly (`insert_user`,
`update_user`, `delete_user`, `active_users`) to perform client-side database
operations on SQLite. These operations automatically set dirty flags and update
column sync metadata.

**Sync Orchestration**: To sync with the backend, tests:
1. Call `retrieve_upload_request()` to collect dirty local records
2. Send the `UploadRequest` to backend via tarpc RPC client
3. Call `store_upload_response()` to clear dirty flags based on server response
4. Call `retrieve_download_request()` to get current sync offsets
5. Send the `DownloadRequest` to backend via RPC client
6. Call `store_download_response()` to merge server data using LWW resolution

This separation allows tests to perform many local operations efficiently while
controlling when RPC communication with the backend occurs.

### Test Orchestration

Test orchestration manages the lifecycle of backend server processes and client
databases for each test.

**SQLite Database Management**: A single SQLite client database is shared
across the test suite as a process-level singleton. Before each test, the
database file is deleted and the schema is recreated from scratch, providing a
clean state without the overhead of creating new temporary directories per test.

**Backend Server with PostgreSQL**: Each test starts its own PostgreSQL container
via testcontainers-rs, ensuring a clean database state. The backend server is
spawned as a child process with the container's database URL and an assigned
port. Connection polling ensures the server is ready before the test proceeds.
Both the server process and PostgreSQL container are automatically cleaned up
when the test completes, providing full isolation between tests.

## Challenges and Considerations

### Backend Server Process Management

The test suite must reliably start and stop backend server processes. Improper
cleanup can leave orphaned processes consuming ports and resources. Tests should
implement graceful shutdown with timeout-based forced termination as fallback.
The `Drop` trait on server handles provides automatic cleanup even when tests
panic.

### Port Allocation

Each backend server instance requires a unique port for the tarpc transport.
Dynamic port allocation (binding to port 0 and reading the assigned port) or
port reservation schemes based on test identifiers can be used. Proper port
management enables parallel test execution without binding conflicts.

### Server Startup Latency

Backend server processes require initialization time before accepting RPC
requests. Tests must implement connection polling with appropriate timeouts
rather than fixed delays. Attempting to establish a tarpc connection enables
reliable startup detection without arbitrary sleep durations.

### Service Trait Synchronization

The tarpc service trait must be shared between the backend server and test
suite. Changes to request/response types require recompilation of both the
backend and test suite. This is handled automatically by Cargo's dependency
tracking, as both crates depend on the shared service definition.

### SQLite Database Management

Each client simulation requires its own SQLite database file. Tests must
properly initialize and switch the carburetor global config when working with
different client databases, as generated client functions rely on global
configuration for database access.

### Test Isolation

Each test operates on an independent PostgreSQL database via a per-test backend
process and container. Client-side isolation is achieved by resetting the shared
SQLite database to a clean state before each test rather than creating a
new database file per test. Because the SQLite database is a shared singleton,
tests must run sequentially (single-threaded) to avoid state leaking between
concurrent tests. Proper process and container cleanup prevents resource
accumulation from repeated test runs.